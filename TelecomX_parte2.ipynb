{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6ns/Zrv6U2jthTcIQbFfM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariantocostanzo/Challange_Telecom_X_parte2/blob/main/TelecomX_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/mariantocostanzo/Challange_Telecom_X_parte2/main/datos_tratados.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n"
      ],
      "metadata": {
        "id": "y1Yp7hVSnUig"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nombres de las columnas\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "Qy_Bu-WScqZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se elimina la columna 'customerID' y las filas que contengan valores nulos\n",
        "df = df.drop(columns=[\"customerID\"])\n",
        "df = df.dropna()\n",
        "\n",
        "# Verificamos que no queden valores nulos\n",
        "print(\"¬øHay valores nulos?:\", df.isnull().values.any())\n",
        "\n",
        "# Mostramos las dimensiones del dataset limpio\n",
        "print(\"Tama√±o del DataFrame despu√©s de limpieza:\", df.shape)\n"
      ],
      "metadata": {
        "id": "C9K928Z8aJ9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Se codifican las variables categ√≥ricas\n",
        "\n",
        "| Tipo de variable                           | M√©todo aplicado|\n",
        "| ------------------------------------------ | ------------------------------------- |\n",
        "| Categ√≥ricas binarias (2 valores)           | Label Encoding (`Yes`‚Üí1, `No`‚Üí0)      |\n",
        "| Categ√≥ricas no binarias (m√°s de 2 valores) | One-Hot Encoding (columnas separadas) |\n"
      ],
      "metadata": {
        "id": "XYHH1aNHfs6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1.'account.Charges.Total' a num√©rico\n",
        "df['account.Charges.Total'] = pd.to_numeric(df['account.Charges.Total'], errors='coerce')\n",
        "\n",
        "# 2. Se identifican las columnas categ√≥ricas\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# 3. Se detectan las binarias (solo 2 valores √∫nicos, ignorando NaNs)\n",
        "binary_cols = [col for col in categorical_cols if df[col].nunique() == 2]\n",
        "\n",
        "# 4. Se aplica Label Encoding a columnas binarias\n",
        "label_encoder = LabelEncoder()\n",
        "for col in binary_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# 5. Se aplica One-Hot Encoding al resto de las columnas categ√≥ricas\n",
        "multi_cat_cols = [col for col in categorical_cols if col not in binary_cols]\n",
        "df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)\n",
        "\n",
        "# Se muestran las primeras filas del DataFrame transformado\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "96TDKT08gUce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Proporci√≥n entre los que cancelaron y no"
      ],
      "metadata": {
        "id": "zyal1Dqtitk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de clientes que cancelaron y los que no\n",
        "cancel_counts = df['Churn'].value_counts()\n",
        "\n",
        "# Total y porcentaje de cada clase\n",
        "print(\"Cantidad por clase:\")\n",
        "print(cancel_counts)\n",
        "\n",
        "print(\"\\nProporci√≥n por clase:\")\n",
        "print(cancel_counts / cancel_counts.sum())\n"
      ],
      "metadata": {
        "id": "sAzZdtj8i0m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úÖ C√≥digo para escalar las variables num√©ricas\n",
        "##Se uso StandardScaler, que estandariza con media 0 y desviaci√≥n 1\n"
      ],
      "metadata": {
        "id": "qV7Z7QJdd8Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identificamos columnas num√©ricas\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numeric_cols.remove('Churn')  # No queremos escalar la variable objetivo\n",
        "\n",
        "# Creamos un escalador\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplicamos el escalado a las columnas num√©ricas\n",
        "df_scaled = df.copy()\n",
        "df_scaled[numeric_cols] = scaler.fit_transform(df_scaled[numeric_cols])\n",
        "\n",
        "# Mostramos un ejemplo\n",
        "df_scaled[numeric_cols].head()\n"
      ],
      "metadata": {
        "id": "qgpvE_Z5eUL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úÖ C√°lculo y vizualici√≥n de la matriz de correlaci√≥n\n"
      ],
      "metadata": {
        "id": "qIhuVAwoe_3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# se ordenan las correlaciones con Churn\n",
        "churn_corr = df.corr(numeric_only=True)[\"Churn\"].drop(\"Churn\").sort_values(ascending=False)\n",
        "\n",
        "# lista de colores basada en los valores de correlaci√≥n\n",
        "colors = sns.color_palette(\"coolwarm\", len(churn_corr))\n",
        "colors = [colors[i] for i in range(len(colors))]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=churn_corr.values, y=churn_corr.index, palette=colors, legend=False)\n",
        "plt.title(\"Correlaci√≥n de variables con 'Churn'\")\n",
        "plt.xlabel(\"Coeficiente de correlaci√≥n\")\n",
        "plt.ylabel(\"Variables\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AFOObJrpfVan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîü Top 10 variables m√°s correlacionadas con Churn:\n",
        "\n",
        "##Las variables con correlaci√≥n positiva alta (m√°s propensas a que el cliente cancele):\n",
        "\n",
        "| Variable                              | Correlaci√≥n alta positiva  |\n",
        "|---------------------------------------|----------------------------|\n",
        "| internet.InternetService_Fiber optic  | +0.3 aprox.                |\n",
        "| account.PaymentMethod_Electronic check| +0.3 aprox.                |\n",
        "| account.Charges.Monthly               | +0.25 aprox.               |\n",
        "| account.PaperlessBilling              | +0.2 aprox.                |\n",
        "| customer.SeniorCitizen                | +0.15 aprox.               |\n",
        "\n",
        "###Estas variables aumentan la probabilidad de que un cliente cancele.\n",
        "\n",
        "##Las variables con correlaci√≥n negativa (m√°s asociadas a permanencia):\n",
        "\n",
        "| Variable                               | Correlaci√≥n negativa     |\n",
        "|----------------------------------------|--------------------------|\n",
        "| customer.tenure                        | ‚Äì0.35 aprox.             |\n",
        "| account.Contract_Two year              | ‚Äì0.3 aprox.              |\n",
        "| internet.TechSupport_No                | ‚Äì0.25 aprox.             |\n",
        "| account.Contract_One year              | ‚Äì0.2 aprox.              |\n",
        "| internet.OnlineSecurity_Yes            | ‚Äì0.2 aprox.              |   \n",
        "\n",
        "###Estas reducen la probabilidad de cancelaci√≥n (fidelidad del cliente).\n",
        "\n"
      ],
      "metadata": {
        "id": "uwsE3fe3Lncz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Se ordenana las correlaciones por valor absoluto\n",
        "churn_corr_abs = churn_corr.abs().sort_values(ascending=False)\n",
        "\n",
        "#top 10 variables\n",
        "top_10_corr = churn_corr.loc[churn_corr_abs.head(10).index]\n",
        "\n",
        "# lista de colores basada en los valores de correlaci√≥n\n",
        "colors = sns.color_palette(\"coolwarm\", len(top_10_corr))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_10_corr.values, y=top_10_corr.index, palette=colors)\n",
        "plt.title(\"Top 10 variables m√°s correlacionadas con 'Churn'\")\n",
        "plt.xlabel(\"Coeficiente de correlaci√≥n\")\n",
        "plt.ylabel(\"Variables\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3QmvSm8EN9gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"df_transformado.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "66e-_vRTVPce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#analisis dirigido#\n",
        "üìä 1. Tiempo de contrato (customer.tenure) √ó Cancelaci√≥n.\n",
        "Se uso un boxplot para ver c√≥mo var√≠a el tiempo de permanencia seg√∫n si el cliente cancel√≥ o no.\n",
        "\n",
        "üìä 2. Gasto total (account.Charges.Total) √ó Cancelaci√≥n.\n",
        "Se uso un scatter plot para comparar cu√°nto gastaron los clientes que cancelaron frente a los que no."
      ],
      "metadata": {
        "id": "VaayzHiBmIPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el dataset transformado\n",
        "df = pd.read_csv(\"df_transformado.csv\")\n",
        "\n",
        "# Estilo\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Gr√°fico 1: Boxplot - Tiempo de contrato vs Cancelaci√≥n\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x=\"Churn\", y=\"customer.tenure\", data=df, palette=[\"lightcoral\", \"lightcoral\"])\n",
        "plt.title(\"Tiempo de contrato seg√∫n cancelaci√≥n\")\n",
        "plt.xlabel(\"Cancelaci√≥n (0 = No, 1 = S√≠)\")\n",
        "plt.ylabel(\"Meses de contrato\")\n",
        "\n",
        "# Gr√°fico 2: Scatter plot - Gasto total vs Cancelaci√≥n\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.scatterplot(x=\"account.Charges.Total\", y=\"Churn\", data=df, alpha=0.5)\n",
        "plt.title(\"Gasto total vs Cancelaci√≥n\")\n",
        "plt.xlabel(\"Gasto total\")\n",
        "plt.ylabel(\"Cancelaci√≥n (0 = No, 1 = S√≠)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SnjbMuTOq8m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separaci√≥n de Datos\n",
        "##üëâ Separa el dataset en dos partes:\n",
        "\n",
        "X: contiene todas las columnas menos \"Churn\" (las caracter√≠sticas o variables independientes).\n",
        "\n",
        "y: contiene la columna \"Churn\" (la variable objetivo que queremos predecir: si el cliente cancela o no).\n",
        "\n"
      ],
      "metadata": {
        "id": "5O4jqfmwrehJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separar variables predictoras y variable objetivo\n",
        "X = df.drop(\"Churn\", axis=1)\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# Dividir 80% entrenamiento y 20% prueba, estratificando por la variable objetivo\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Verificaci√≥n de tama√±os\n",
        "print(\"Tama√±o de entrenamiento:\", X_train.shape[0])\n",
        "print(\"Tama√±o de prueba:\", X_test.shape[0])\n",
        "print(\"Total:\", df.shape[0])\n"
      ],
      "metadata": {
        "id": "pazAtUStrivY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creaci√≥n de Modelos\n",
        "\n",
        "‚úÖ 1. Modelo 1: Regresi√≥n Log√≠stica (requiere normalizaci√≥n)\n",
        "Usa distancias internas y c√°lculo de coeficientes ‚Üí necesita que las variables est√©n en la misma escala.\n",
        "\n",
        "‚úÖ 2. Modelo 2: Random Forest (no requiere normalizaci√≥n)\n",
        "Basado en √°rboles ‚Üí no le afecta la escala.\n",
        "\n"
      ],
      "metadata": {
        "id": "q3pNNIdMtBWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Separar features y target\n",
        "X = df.drop(\"Churn\", axis=1)\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# MODELO 1: Regresi√≥n Log√≠stica (con imputaci√≥n y normalizaci√≥n)\n",
        "# ================================\n",
        "pipeline_lr = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "\n",
        "# ================================\n",
        "# MODELO 2: Random Forest (con imputaci√≥n, sin normalizaci√≥n)\n",
        "# ================================\n",
        "pipeline_rf = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"model\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "pipeline_rf.fit(X_train, y_train)\n",
        "y_pred_rf = pipeline_rf.predict(X_test)\n",
        "\n",
        "# ================================\n",
        "# Evaluaci√≥n\n",
        "# ================================\n",
        "print(\"üîπ Regresi√≥n Log√≠stica\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"üîπ Random Forest\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "DuZAN3Wto34y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
        "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "\n",
        "metrics_lr = {\n",
        "    'Acur√°cia': report_lr['accuracy'],\n",
        "    'Precision': report_lr['1']['precision'],\n",
        "    'Recall': report_lr['1']['recall'],\n",
        "    'F1-Score': report_lr['1']['f1-score']\n",
        "}\n",
        "\n",
        "metrics_rf = {\n",
        "    'Acur√°cia': report_rf['accuracy'],\n",
        "    'Precision': report_rf['1']['precision'],\n",
        "    'Recall': report_rf['1']['recall'],\n",
        "    'F1-Score': report_rf['1']['f1-score']\n",
        "}\n",
        "\n",
        "# Creaci√≥n del  DataFrame para el plotting\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metrica': metrics_lr.keys(),\n",
        "    'Regresi√≥n log√≠stica': metrics_lr.values(),\n",
        "    'Random Forest': metrics_rf.values()\n",
        "})\n",
        "\n",
        "metrics_df_melted = metrics_df.melt(id_vars='Metrica', var_name='Modelo', value_name='Score')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metrica', y='Score', hue='Modelo', data=metrics_df_melted, palette=[\"lightblue\", \"lightpink\"])\n",
        "plt.title('Comparaci√≥n del rendimiento del modelo')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vy8XyEeIrZwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e6355f2"
      },
      "source": [
        "## Matriz de confusi√≥n\n",
        "\n",
        "Matriz de confusi√≥n de cada modelo para ver qu√© tan bien se desempe√±an al clasificar a los clientes que abandonan y los que no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17561c97"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Matriz de Confusi√≥n para regresi√≥n log√≠stica\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confusi√≥n - Regresi√≥n log√≠stica')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks([0.5, 1.5], ['No Churn (0)', 'Churn (1)'])\n",
        "plt.yticks([0.5, 1.5], ['No Churn (0)', 'Churn (1)'])\n",
        "plt.show()\n",
        "\n",
        "# Matriz de Confusi√≥nRandom Forest\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confusi√≥n- Random Forest')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks([0.5, 1.5], ['No Churn (0)', 'Churn (1)'])\n",
        "plt.yticks([0.5, 1.5], ['No Churn (0)', 'Churn (1)'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Considerando la importancia de identificar los casos reales de cancelaci√≥n (Recall) y el equilibrio general entre precisi√≥n y recall (Puntuaci√≥n F1) para la clase de cancelaci√≥n, el modelo de Regresi√≥n Log√≠stica parece tener un rendimiento ligeramente mejor para este problema espec√≠fico, aunque la precisi√≥n general sea similar."
      ],
      "metadata": {
        "id": "hMLJy3m9ty9q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917df12c"
      },
      "source": [
        "# Informe Detallado sobre la Cancelaci√≥n de Clientes\n",
        "\n",
        "Se presenta un an√°lisis de los factores que influyen en la cancelaci√≥n de clientes (Churn) y se eval√∫a el rendimiento de dos modelos de clasificaci√≥n para predecir este comportamiento.\n",
        "\n",
        "## 1. Factores Clave que Influyen en la Cancelaci√≥n\n",
        "\n",
        "Bas√°ndonos en el an√°lisis de correlaci√≥n, las variables que muestran una mayor influencia (positiva o negativa) en la cancelaci√≥n son:\n",
        "\n",
        "*   **Correlaci√≥n Positiva Alta (mayor probabilidad de cancelaci√≥n):**\n",
        "    *   `internet.InternetService_Fiber optic`: Los clientes con servicio de fibra √≥ptica tienden a cancelar m√°s.\n",
        "    *   `account.PaymentMethod_Electronic check`: El m√©todo de pago por cheque electr√≥nico est√° asociado a una mayor tasa de cancelaci√≥n.\n",
        "    *   `account.Charges.Monthly`: Un mayor cargo mensual se correlaciona positivamente con la cancelaci√≥n.\n",
        "    *   `account.PaperlessBilling`: Los clientes con facturaci√≥n electr√≥nica tienden a cancelar m√°s.\n",
        "    *   `customer.SeniorCitizen`: Los clientes de la tercera edad tienen una mayor propensi√≥n a cancelar.\n",
        "\n",
        "*   **Correlaci√≥n Negativa Alta (menor probabilidad de cancelaci√≥n - mayor fidelidad):**\n",
        "    *   `customer.tenure`: Los clientes con mayor tiempo de permanencia son menos propensos a cancelar.\n",
        "    *   `account.Contract_Two year`: Los contratos de dos a√±os est√°n fuertemente asociados a la permanencia.\n",
        "    *   `internet.TechSupport_No internet service`: La falta de soporte t√©cnico est√° relacionada con una mayor cancelaci√≥n.\n",
        "    *   `account.Contract_One year`: Los contratos de un a√±o tambi√©n reducen la probabilidad de cancelaci√≥n, aunque en menor medida que los de dos a√±os.\n",
        "    *   `internet.OnlineSecurity_Yes`: Tener seguridad online se asocia a una menor cancelaci√≥n.\n",
        "\n",
        "## 2. Rendimiento de los Modelos de Clasificaci√≥n\n",
        "\n",
        "Se evaluaron dos modelos: Regresi√≥n Log√≠stica y Random Forest. Los resultados obtenidos en el conjunto de prueba son los siguientes:\n",
        "\n",
        "| M√©trica   | Regresi√≥n Log√≠stica | Random Forest |\n",
        "| :-------- | :------------------ | :------------ |\n",
        "| Accuracy  | 0.794               | 0.785         |\n",
        "| Precision (Churn) | 0.637               | 0.630         |\n",
        "| Recall (Churn)    | 0.521               | 0.460         |\n",
        "| F1-Score (Churn)  | 0.574               | 0.532         |\n",
        "\n",
        "**An√°lisis del Rendimiento:**\n",
        "\n",
        "*   Ambos modelos tienen una precisi√≥n general similar.\n",
        "*   La **Regresi√≥n Log√≠stica** muestra un rendimiento ligeramente mejor en las m√©tricas clave para la clase minoritaria (Churn):\n",
        "    *   Mayor **Recall**, lo que significa que identifica una mayor proporci√≥n de clientes que realmente cancelan. Esto es crucial para implementar estrategias de retenci√≥n.\n",
        "    *   Mayor **Puntuaci√≥n F1**, que indica un mejor equilibrio entre precisi√≥n y recall para la clase de inter√©s.\n",
        "*   El **Random Forest**, aunque con una precisi√≥n similar, tiene un recall m√°s bajo, lo que implica que deja pasar a m√°s clientes que s√≠ cancelar√°n.\n",
        "\n",
        "**Matrices de Confusi√≥n:**\n",
        "\n",
        "Las matrices de confusi√≥n detallan las predicciones de cada modelo:\n",
        "\n",
        "**Regresi√≥n Log√≠stica:**\n",
        "*   Verdaderos Positivos (predice Churn correctamente): 195\n",
        "*   Falsos Positivos (predice Churn incorrectamente): 111\n",
        "*   Verdaderos Negativos (predice No Churn correctamente): 924\n",
        "*   Falsos Negativos (predice No Churn incorrectamente): 179\n",
        "\n",
        "**Random Forest:**\n",
        "*   Verdaderos Positivos: 172\n",
        "*   Falsos Positivos: 101\n",
        "*   Verdaderos Negativos: 934\n",
        "*   Falsos Negativos: 202\n",
        "\n",
        "La Regresi√≥n Log√≠stica identifica 195 casos de Churn correctamente, mientras que Random Forest identifica 172. La Regresi√≥n Log√≠stica tambi√©n tiene menos Falsos Negativos (179 vs 202), lo que refuerza su mejor capacidad para detectar la cancelaci√≥n.\n",
        "\n",
        "## 3. Estrategias de Retenci√≥n Propuestas\n",
        "\n",
        "Bas√°ndonos en los factores clave de influencia y el rendimiento del modelo de Regresi√≥n Log√≠stica (considerado ligeramente superior para este caso):\n",
        "\n",
        "*   **Foco en Clientes con Fibra √ìptica y Pago Electr√≥nico:** Implementar programas de satisfacci√≥n espec√≠ficos o revisar los posibles puntos de negativos para clientes que usan estos servicios o m√©todos de pago.\n",
        "*   **Monitoreo de Cargos Mensuales:** Identificar a los clientes con cargos mensuales elevados y evaluar la posibilidad de ofrecerles planes alternativos o descuentos antes de que consideren cancelar.\n",
        "*   **Incentivar Contratos a Largo Plazo:** Promover activamente los contratos de uno y, especialmente, de dos a√±os, destacando sus beneficios y ofreciendo incentivos por la renovaci√≥n a largo plazo.\n",
        "*   **Mejorar el Soporte T√©cnico:** Dado que la falta de soporte t√©cnico se asocia con la cancelaci√≥n, invertir en mejorar la calidad y accesibilidad del soporte puede ser una estrategia de retenci√≥n efectiva.\n",
        "*   **Resaltar los Beneficios de la Seguridad Online:** Educar a los clientes sobre la importancia y los beneficios de la seguridad online para fomentar su adopci√≥n y, potencialmente, aumentar la permanencia.\n",
        "*   **Programas para Clientes Antiguos:** Reconocer y recompensar la fidelidad de los clientes con mayor antig√ºedad (`customer.tenure`) para reforzar su compromiso.\n",
        "\n",
        "## Conclusi√≥n\n",
        "\n",
        "El an√°lisis de datos ha revelado que factores como el tipo de servicio de internet, el m√©todo de pago, el cargo mensual y el tipo de contrato son determinantes en la decisi√≥n de un cliente de cancelar. El modelo de Regresi√≥n Log√≠stica demostr√≥ ser levemente mejor en la identificaci√≥n de clientes propensos a cancelar. Las estrategias de retenci√≥n deben enfocarse en abordar los puntos d√©biles identificados en los factores de alta correlaci√≥n positiva e incentivar aquellos asociados a la permanencia."
      ]
    }
  ]
}